{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      So we want our activation function to not shift the gradient towards zero.\n",
    "      Output of the activation function should be symmetrical at zero so that the gradients do not shift to a particular direction.\n",
    "      Activation functions are applied after every layer and need to be calculated millions of times in deep networks. Hence, they should be computationally inexpensive to calculate.\n",
    "      As mentioned, neural networks are trained using the gradient descent process, hence the layers in the model need to differentiable or at least differentiable in parts. This is a necessary requirement for a function to work as activation function layer.\n",
    "  \n",
    "        Sigmoid\n",
    "        This activation function is here only for historical reasons and never used in real models. It is computationally expensive, causes vanishing gradient problem and not zero-centred. This method is generally used for binary classification problems.\n",
    "        \n",
    "        sınıflandırma işlemlerinde evet hayır diyebileceğimiz durumlarda kullanılır.Binary çıktılarda kullanılır\n",
    "        \n",
    "        Softmax\n",
    "        Similar to sigmoid, it produces values in the range of 0–1 therefore it is used as the final layer in classification models.\n",
    "        Çok sınıflı sınıflandırma algoritması olasılığını veriyor\n",
    "        \n",
    "        Relu\n",
    "        Sparse activation: For example, in a randomly initialized network, only about 50% of hidden units are activated (having a non-zero output).\n",
    "    Better gradient propagation: Fewer vanishing gradient problems compared to sigmoidal activation functions that saturate in both directions\n",
    "    ReLUs aren’t without any drawbacks some of them are that ReLU is Non Zero centered and is non differentiable at Zero, but differentiable anywhere else.\n",
    "    Another problem we see in ReLU is the Dying ReLU problem where some ReLU Neurons essentially die for all inputs and remain inactive no matter what input is supplied, here no gradient flows and if large number of dead neurons are there in a Neural Network it’s performance is affected, this can be corrected by making use of what is called Leaky ReLU where slope is changed left of x=0 in above figure and thus causing a leak and extending the range of ReLU.\n",
    "    With Leaky ReLU there is a small negative slope, so instead of not firing at all for large gradients, our neurons do output some value and that makes our layer much more optimized too.\n",
    "        \n",
    "        \n",
    "        Tüm nörünları aynı anda aktive etmiyor. neagtif giriş değerini 0 a çevirir\n",
    "        \n",
    "        Elu\n",
    "        Exponential Linear Units are are used to speed up the deep learning process, this is done by making the mean activations closer to Zero, here an alpha constant is used which must be a positive number.\n",
    "        ELU have been shown to produce more accurate results than ReLU and also converge faster. ELU and ReLU are same for positive inputs, but for negative inputs ELU smoothes (to -alpha) slowly whereas ReLU smooths sharply.\n",
    "        \n",
    "        Tanh\n",
    "        If you compare it to sigmoid, it solves just one problem of being zero-centred.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### Optimizer\n",
    "\n",
    "Momentum ile “schoastic gradient descent”in salınımları azaltılarak daha hızlı ve tutarlı bir optimizasyon algoritması oluşturulabilir.\n",
    "Optimizers are mathematical functions which are dependent on model’s learnable parameters i.e Weights & Biases. Optimizers help to know how to change weights and learning rate of neural network to reduce the losses.\n",
    "\n",
    "Loss functionu en aza indirmek ve accuracy i en üst seviyeye çıkarmaya çalışır\n",
    "\n",
    "Gradient Descent\n",
    "\n",
    "Stochastic Gradient Descent\n",
    "\n",
    "Advantages of Stochastic Gradient Descent\n",
    "Frequent updates of model parameter\n",
    "Requires less Memory.\n",
    "Allows the use of large data sets as it has to update only one example at a time.\n",
    "Disadvantages of Stochastic Gradient Descent\n",
    "The frequent can also result in noisy gradients which may cause the error to increase instead of decreasing it.\n",
    "High Variance.\n",
    "Frequent updates are computationally expensive\n",
    "\n",
    "RMS Prop\n",
    "    \n",
    "    uyarlanabilir bir öğrenme  hızı kullanır. Hata fazlayken adım büyük, küçükken küçüktür\n",
    "\n",
    "AdaGrad\n",
    "In all the algorithms that we discussed previously the learning rate remains constant. The intuition behind AdaGrad is can we use different Learning Rates for each and every neuron for each and every hidden layer based on different iterations.\n",
    "Advantages of AdaGrad\n",
    "Learning Rate changes adaptively with iterations.\n",
    "It is able to train sparse data as well.\n",
    "Disadvantage of AdaGrad\n",
    "If the neural network is deep the learning rate becomes very small number which will cause dead neuron problem.\n",
    "\n",
    "AdaDelta\n",
    "Adadelta is an extension of Adagrad and it also tries to reduce Adagrad’s aggressive, monotonically reducing the learning rate and remove decaying learning rate problem. In Adadelta we do not need to set the default learning rate as we take the ratio of the running average of the previous time steps to the current gradient.\n",
    "Advantages of Adadelta\n",
    "The main advantage of AdaDelta is that we do not need to set a default learning rate.\n",
    "Disadvantages of Adadelta\n",
    "Computationally expensive\n",
    "\n",
    "Adam\n",
    "uyarlanabilir bir öğrenme oranı yöntemidir\n",
    "sinir ağının her ağırlığı için öğrenme oranını uyarlamak için 1. ve 2. gradyan anlarının tahminlerini kullanmasıdır\n",
    "Easy to implement\n",
    "Computationally efficient.\n",
    "Little memory requirements\n",
    "        \n",
    "\n",
    "\n",
    "How to choose optimizers?\n",
    "If the data is sparse, use the self-applicable methods, namely Adagrad, Adadelta, RMSprop, Adam.\n",
    "RMSprop, Adadelta, Adam have similar effects in many cases.\n",
    "Adam just added bias-correction and momentum on the basis of RMSprop,\n",
    "As the gradient becomes sparse, Adam will perform better than RMSprop.\n",
    "Epoch\n",
    "\n",
    "Batch size"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Derin öğrenme modellerinde genelde varsayalan olarak kullanılan optimizasyon algoritması stochastic gradient descent (SGD).\n",
    "Bununla birlikte şekil 6'da görüleceği üzere schoastic gradient descent diğer yöntemlere göre daha yavaş çalışıyor.\n",
    "Stochastic Gradient Descent (SGD) bazı problemlerde çok kötü sonuç verebilmektedir; özellikle resim tanıma problemlerinde.\n",
    "Adaptive algoritmalar öğrenme hızını (learning rate) kendisi öğrenmektedir ve dinamiktir.\n",
    "AdaGrad seyrek parametreler için büyük güncellemeler yaparken sık parametreler için daha küçük güncellemeler yapar. Bu nedenle NLP ve resim tanıma gibi seyrek veriler için daha uygundur.\n",
    "AdaGrad’da her parametrenin kendi öğrenme hızı vardır ve algoritmanın özelliklerine bağlı olarak öğrenme oranı giderek azalmaktadır. Bu nedenle öğreneme oranı giderek azalır ve zamanın bir noktasında sistem öğrenmeyi bırakır. Bu AdaGrad’ın en büyük dez avantajıdır.\n",
    "RMSprop ve benzeri olan AdaDelta, AdaGrad’ın bu sorununu çözerek bu hızlı düşüşü önler.\n",
    "Adam veya adaptif momentum AdaDelta’ya benzer bir algoritmadır. AdaDelta’dan farklı olarak parametrelerin her birinin öğrenme oranlarının yanısıra momentum değişikliklerini de önbellekte (cache) saklar; yani RMSprop ve momentumu birleştirir.\n",
    "Adaptif algoritmalar hız açısından SGD’den daha iyi performans göstermektedir. Bununla birlikte SGD momentum ile kullanıldığında, SGD’nin başarım açısından adaptif yöntemlere göre daha yüksek başarım gösterdiği bazı durumlarda var. Örnek için 2017 yılında yayınlanan “The Marginal Value of Adaptive Gradient Methods in Machine Learning”makalesine bakılabilir.[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://atcold.github.io/pytorch-Deep-Learning/tr/week05/05-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nesterov Accelerated Gradient\n",
    "One small variant to Momentum optimization, proposed by Yurii Nesterov in 1983,\n",
    "13\n",
    "is almost always faster than vanilla Momentum optimization. The idea of Nesterov\n",
    "Momentum optimization, or Nesterov Accelerated Gradient (NAG), is to measure the\n",
    "gradient of the cost function not at the local position but slightly ahead in the direc‐\n",
    "tion of the momentum (see Equation 11-5). The only difference from vanilla\n",
    "Momentum optimization is that the gradient is measured at θ + βm rather than at θ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
